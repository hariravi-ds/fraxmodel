{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01553d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "def _tail_metrics(name: str, y_true: np.ndarray, y_pred: np.ndarray, thresholds=(3.0, 5.0, 10.0)):\n",
    "    print(f\"\\n{name} tail metrics:\")\n",
    "    for t in thresholds:\n",
    "        mask = y_true >= t\n",
    "        n = int(mask.sum())\n",
    "        if n < 5:\n",
    "            print(f\"  y >= {t}: n={n} (too few)\")\n",
    "            continue\n",
    "        mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
    "        r2 = r2_score(y_true[mask], y_pred[mask])\n",
    "        print(f\"  y >= {t}: n={n} | MAE={mae:.3f} | R2={r2:.4f}\")\n",
    "\n",
    "\n",
    "def train_fraxplus_surrogates_final(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "    hip_high_threshold: float = 2.0,\n",
    "    clamp_0_100: bool = True,\n",
    "    tail_thresholds=(3.0, 5.0, 10.0),\n",
    "):\n",
    "    base = df.drop(\n",
    "        columns=[c for c in [\"continent\", \"bmi_units\",\n",
    "                             \"scanner\"] if c in df.columns],\n",
    "        errors=\"ignore\"\n",
    "    ).copy()\n",
    "\n",
    "    base = base.dropna(subset=[\"mof_risk\", \"hip_risk\"]).copy()\n",
    "    if \"us_group\" in base.columns:\n",
    "        base = base.dropna(subset=[\"us_group\"]).copy()\n",
    "\n",
    "    y_mof = base[\"mof_risk\"].astype(float).to_numpy()\n",
    "    y_hip = base[\"hip_risk\"].astype(float).to_numpy()\n",
    "\n",
    "    X = base.drop(columns=[\"mof_risk\", \"hip_risk\"])\n",
    "    if \"us_group\" in X.columns:\n",
    "        X = pd.get_dummies(X, columns=[\"us_group\"], drop_first=False)\n",
    "\n",
    "    X_train, X_test, y_mof_train, y_mof_test, y_hip_train, y_hip_test = train_test_split(\n",
    "        X, y_mof, y_hip, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # ---- MOF model ----\n",
    "    mof_model = HistGradientBoostingRegressor(\n",
    "        learning_rate=0.05,\n",
    "        max_iter=2000,\n",
    "        l2_regularization=0.5,\n",
    "        early_stopping=True,\n",
    "        random_state=random_state,\n",
    "        max_depth=4,\n",
    "        min_samples_leaf=20,\n",
    "    )\n",
    "\n",
    "    print(\"\\nTraining MOF (log1p)... {'max_depth': 4, 'min_samples_leaf': 20}\")\n",
    "    mof_model.fit(X_train, np.log1p(y_mof_train))\n",
    "\n",
    "    mof_pred_t = mof_model.predict(X_test)\n",
    "    mof_pred = np.expm1(mof_pred_t)\n",
    "\n",
    "    # ---- HIP two-stage ----\n",
    "    y_high = (y_hip_train >= hip_high_threshold).astype(int)\n",
    "\n",
    "    hip_clf = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_iter=2000,\n",
    "        l2_regularization=0.5,\n",
    "        early_stopping=True,\n",
    "        random_state=random_state,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=40,\n",
    "    )\n",
    "\n",
    "    print(f\"Training Hip classifier (hip_risk >= {hip_high_threshold})...\")\n",
    "    hip_clf.fit(X_train, y_high)\n",
    "\n",
    "    low_mask = y_hip_train < hip_high_threshold\n",
    "    high_mask = ~low_mask\n",
    "\n",
    "    hip_reg_low = HistGradientBoostingRegressor(\n",
    "        learning_rate=0.05,\n",
    "        max_iter=3000,\n",
    "        l2_regularization=0.5,\n",
    "        early_stopping=True,\n",
    "        random_state=random_state,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=40,\n",
    "    )\n",
    "\n",
    "    hip_reg_high = HistGradientBoostingRegressor(\n",
    "        learning_rate=0.03,\n",
    "        max_iter=4000,\n",
    "        l2_regularization=0.2,\n",
    "        early_stopping=True,\n",
    "        random_state=random_state,\n",
    "        max_depth=4,\n",
    "        min_samples_leaf=15,\n",
    "    )\n",
    "\n",
    "    print(f\"Training Hip regressor LOW (n={int(low_mask.sum())})...\")\n",
    "    hip_reg_low.fit(X_train[low_mask], np.log1p(y_hip_train[low_mask]))\n",
    "\n",
    "    print(f\"Training Hip regressor HIGH (n={int(high_mask.sum())})...\")\n",
    "    hip_reg_high.fit(X_train[high_mask], np.log1p(y_hip_train[high_mask]))\n",
    "\n",
    "    p_high = hip_clf.predict_proba(X_test)[:, 1]  # keep T=1.0 (best)\n",
    "    hip_pred_low_t = hip_reg_low.predict(X_test)\n",
    "    hip_pred_high_t = hip_reg_high.predict(X_test)\n",
    "\n",
    "    hip_pred_t = (1 - p_high) * hip_pred_low_t + p_high * hip_pred_high_t\n",
    "    hip_pred = np.expm1(hip_pred_t)\n",
    "\n",
    "    # ---- safety clamp ----\n",
    "    if clamp_0_100:\n",
    "        mof_pred = np.clip(mof_pred, 0.0, 100.0)\n",
    "        hip_pred = np.clip(hip_pred, 0.0, 100.0)\n",
    "\n",
    "    # ---- metrics ----\n",
    "    print(\"\\n=== PERFORMANCE (holdout) ===\")\n",
    "    print(\n",
    "        f\"MOF  original: MAE={mean_absolute_error(y_mof_test, mof_pred):.3f} | R2={r2_score(y_mof_test, mof_pred):.4f}\")\n",
    "    print(\n",
    "        f\"MOF  log1p:    MAE={mean_absolute_error(np.log1p(y_mof_test), mof_pred_t):.3f} | R2={r2_score(np.log1p(y_mof_test), mof_pred_t):.4f}\")\n",
    "\n",
    "    print(\n",
    "        f\"Hip  original: MAE={mean_absolute_error(y_hip_test, hip_pred):.3f} | R2={r2_score(y_hip_test, hip_pred):.4f}\")\n",
    "    print(\n",
    "        f\"Hip  log1p:    MAE={mean_absolute_error(np.log1p(y_hip_test), hip_pred_t):.3f} | R2={r2_score(np.log1p(y_hip_test), hip_pred_t):.4f}\")\n",
    "\n",
    "    _tail_metrics(\"MOF\", y_mof_test, mof_pred, thresholds=tail_thresholds)\n",
    "    _tail_metrics(\"Hip\", y_hip_test, hip_pred, thresholds=tail_thresholds)\n",
    "\n",
    "    return {\n",
    "        \"mof_model\": mof_model,\n",
    "        \"hip_clf\": hip_clf,\n",
    "        \"hip_reg_low\": hip_reg_low,\n",
    "        \"hip_reg_high\": hip_reg_high,\n",
    "        \"feature_columns\": list(X.columns),\n",
    "        \"hip_high_threshold\": hip_high_threshold,\n",
    "    }\n",
    "\n",
    "\n",
    "def save_models(models, path=\"fraxplus_models.pkl\"):\n",
    "    joblib.dump(models, path)\n",
    "    print(f\"Models saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f69d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/hariprasannaa/fraxdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1011dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MOF (log1p)... {'max_depth': 4, 'min_samples_leaf': 20}\n",
      "Training Hip classifier (hip_risk >= 2.0)...\n",
      "Training Hip regressor LOW (n=146)...\n",
      "Training Hip regressor HIGH (n=158)...\n",
      "\n",
      "=== PERFORMANCE (holdout) ===\n",
      "MOF  original: MAE=0.774 | R2=0.9353\n",
      "MOF  log1p:    MAE=0.089 | R2=0.9675\n",
      "Hip  original: MAE=0.544 | R2=0.9195\n",
      "Hip  log1p:    MAE=0.175 | R2=0.9239\n",
      "\n",
      "MOF tail metrics:\n",
      "  y >= 3.0: n=58 | MAE=0.944 | R2=0.9031\n",
      "  y >= 5.0: n=42 | MAE=1.161 | R2=0.8471\n",
      "  y >= 10.0: n=19 | MAE=1.754 | R2=0.6268\n",
      "\n",
      "Hip tail metrics:\n",
      "  y >= 3.0: n=26 | MAE=0.924 | R2=0.8445\n",
      "  y >= 5.0: n=12 | MAE=1.376 | R2=0.7820\n",
      "  y >= 10.0: n=2 (too few)\n",
      "Models saved to fraxplus_models.pkl\n"
     ]
    }
   ],
   "source": [
    "models = train_fraxplus_surrogates_final(data, hip_high_threshold=2.0)\n",
    "save_models(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
